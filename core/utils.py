import re
import json
import unicodedata
import hashlib
from pypinyin import lazy_pinyin
import logging
from typing import Any, Dict



logger = logging.getLogger(__name__)

def make_safe_storage_path(filename: str, prefix: str = "") -> str:
    logger.info(f"Sanitizing filename: {filename}")
    # 1. å»é™¤ä¸å¯è§å­—ç¬¦ + æ­£è§„åŒ–ä¸º NFC
    filename = unicodedata.normalize("NFKC", filename)

    # 2. ä¸­æ–‡è½¬æ‹¼éŸ³ï¼ˆåªä¿ç•™æ–‡ä»¶ä¸»åï¼Œåç¼€ä¸å¤„ç†ï¼‰
    if "." in filename:
        name_part, ext = filename.rsplit(".", 1)
    else:
        name_part, ext = filename, ""

    # è½¬ä¸ºæ‹¼éŸ³ï¼ˆå¦‚ï¼š'å¤©ç¿”è¿ªæ™Ÿï¼ˆæ·±åœ³ï¼‰å‘ç¥¨' â†’ 'tianxiangdisheng_shenzhen_fapiao'ï¼‰
    pinyin_name = "_".join(lazy_pinyin(name_part))

    # 3. ä¿ç•™è‹±æ–‡ã€æ•°å­—ã€ä¸‹åˆ’çº¿ã€çŸ­æ¨ªçº¿å’Œç‚¹ï¼Œç§»é™¤éæ³•å­—ç¬¦
    pinyin_name = re.sub(r"[^\w.-]", "_", pinyin_name)
    ext = re.sub(r"[^\w]", "", ext)

    # 4. é™é•¿ + é˜²é‡å¤ hash
    if len(pinyin_name) > 80:
        hash_suffix = hashlib.md5(filename.encode()).hexdigest()[:8]
        pinyin_name = pinyin_name[:70] + "_" + hash_suffix

    # 5. ç»„è£…æœ€ç»ˆæ–‡ä»¶å
    final_filename = f"{pinyin_name}.{ext}" if ext else pinyin_name

    # 6. å¯é€‰å‰ç¼€è·¯å¾„ï¼ˆå¦‚ '2025-06-23'ï¼‰
    if prefix:
        result = f"{prefix}/{final_filename}"
    else:
        result = final_filename
    logger.info(f"Sanitized filename result: {result}")
    return result


def clean_and_parse_json(text: Any) -> Dict:
    """
    æ¸…æ´—å¹¶è§£æ JSON å†…å®¹ã€‚
    æ”¯æŒä»¥ä¸‹è¾“å…¥ç±»å‹ï¼š
    - dictï¼šç›´æ¥è¿”å›
    - strï¼šè‡ªåŠ¨æ¸…æ´— ```json åŒ…è£¹å¹¶è§£æ
    - bytesï¼šå…ˆè§£ç å†è§£æ
    """
    logger.info("Cleaning and parsing JSON input.")

    # ğŸ§© æƒ…å†µ 1ï¼šå¦‚æœå·²ç»æ˜¯ dictï¼Œç›´æ¥è¿”å›
    if isinstance(text, dict):
        logger.info("Input is already a dict, returning directly.")
        return text

    # ğŸ§© æƒ…å†µ 2ï¼šå¦‚æœæ˜¯ bytesï¼Œå…ˆè½¬æˆ str
    if isinstance(text, bytes):
        try:
            text = text.decode("utf-8")
        except Exception as e:
            logger.warning(f"Failed to decode bytes input: {e}")
            raise ValueError("Invalid bytes input for JSON parsing")

    # ğŸ§© æƒ…å†µ 3ï¼šå¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æ¸…æ´—å¹¶è§£æ
    if isinstance(text, str):
        try:
            # å»æ‰ markdown ä»£ç å—åŒ…è£…ï¼Œå¦‚ ```json ... ```
            cleaned = re.sub(r"^```(?:json|python)?\s*", "", text.strip(), flags=re.IGNORECASE)
            cleaned = re.sub(r"\s*```$", "", cleaned.strip())

            # å°è¯•è§£æ JSON
            result = json.loads(cleaned)
            logger.info("JSON parsed successfully.")
            return result
        except json.JSONDecodeError as e:
            logger.warning(f"Primary JSON decode failed: {e}. Trying literal_eval fallback...")

            # å…¼å®¹å•å¼•å· JSON çš„ fallback
            import ast
            try:
                result = ast.literal_eval(cleaned)
                if isinstance(result, dict):
                    logger.info("Parsed using ast.literal_eval fallback.")
                    return result
                else:
                    raise ValueError("Parsed object is not a dict")
            except Exception as e2:
                logger.exception(f"Failed to clean and parse JSON: {str(e2)}")
                raise ValueError(f"Cannot parse JSON string: {text[:200]}") from e2

    # ğŸ§© å…¶ä»–ç±»å‹ä¸æ”¯æŒ
    raise TypeError(f"Unsupported input type: {type(text)}")
